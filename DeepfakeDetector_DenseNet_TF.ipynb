{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnucramesh/deepfake-detection/blob/master/DeepfakeDetector_DenseNet_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Step 1: Upload the API key file provided by kaggle to a location in google drive\n",
        "Step 2: Set the config file as the environemnt variable\n",
        "Step 5: Change working directory\n",
        "Step 3: Get kaggle download link from kaggle \n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "\n",
        "!pip install kaggle\n",
        "\n",
        "\n",
        "PATH = '/Users/vishnu/Work/uni/VISOPE/deepfake-image-detector/dataset'\n",
        "\n",
        "# set kaggle config file directory\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = PATH\n",
        "\n",
        "%cd $PATH\n",
        "\n",
        "!kaggle datasets download -d xhlulu/140k-real-and-fake-faces --unzip"
      ],
      "metadata": {
        "id": "25yGkrDNg2KP"
      },
      "id": "25yGkrDNg2KP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "ba770de6-55e4-4d4c-8d98-c1eaec7d9b99",
      "metadata": {
        "id": "ba770de6-55e4-4d4c-8d98-c1eaec7d9b99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04bad0ed-3151-4b21-f371-9b0a48935464"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (3.5.3)\r\n",
            "Requirement already satisfied: pillow in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (9.2.0)\r\n",
            "Requirement already satisfied: sklearn in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (0.0)\r\n",
            "Requirement already satisfied: opencv-python in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (4.6.0.66)\r\n",
            "Requirement already satisfied: tqdm in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (4.64.1)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.4.4-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (4.37.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (1.23.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from sklearn) (1.1.2)\n",
            "Collecting pytz>=2020.1\n",
            "  Downloading pytz-2022.2.1-py2.py3-none-any.whl (500 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.6/500.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.9.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in ./.pyenv/versions/3.8.5/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Installing collected packages: pytz, pandas\n",
            "Successfully installed pandas-1.4.4 pytz-2022.2.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install matplotlib pillow sklearn opencv-python tqdm pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fae92eb5-13d4-4d11-883c-f7a58dd98f5d",
      "metadata": {
        "id": "fae92eb5-13d4-4d11-883c-f7a58dd98f5d"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(pretrained):\n",
        "    model = Sequential([\n",
        "        pretrained,\n",
        "        layers.GlobalAveragePooling2D(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',\n",
        "        optimizer=Adam(),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "qqfvoiVfi0my"
      },
      "id": "qqfvoiVfi0my",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7ca72582-b4ce-4584-8d3d-83b4c3ab1c30",
      "metadata": {
        "id": "7ca72582-b4ce-4584-8d3d-83b4c3ab1c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81163244-3580-4e6c-d003-a1f9a3e67915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n",
            "Found 20000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "base_path = '/Users/vishnu/Work/uni/VISOPE/deepfake-image-detector/dataset/real_vs_fake/real-vs-fake/'\n",
        "image_gen = ImageDataGenerator(rescale=1./255.)\n",
        "batch_size = 64\n",
        "train_flow = image_gen.flow_from_directory(\n",
        "    base_path + 'train/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "valid_flow = image_gen.flow_from_directory(\n",
        "    base_path + 'valid/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary'\n",
        ")\n",
        "test_flow = image_gen.flow_from_directory(\n",
        "    base_path + 'test/',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    class_mode='binary'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "densenet = DenseNet121(\n",
        "    include_top=False,\n",
        "    input_shape=(224,224,3)\n",
        ")\n",
        "model = build_model(densenet)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZT4e3Rf3i18v",
        "outputId": "9211a6ac-e737-461a-d450-f69eaf759b69"
      },
      "id": "ZT4e3Rf3i18v",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-09-14 17:13:17.378660: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29084464/29084464 [==============================] - 3s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,038,529\n",
            "Trainable params: 6,954,881\n",
            "Non-trainable params: 83,648\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps = 1000//64\n",
        "valid_steps = 200//64\n",
        "\n",
        "earlystop_callback = EarlyStopping(monitor='loss', patience=3)\n",
        "checkpoint_callback = ModelCheckpoint(filepath=f\"model.hdf5\", \n",
        "                             monitor='val_loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "history = model.fit(\n",
        "      train_flow,\n",
        "      epochs=10,\n",
        "      steps_per_epoch = train_steps,\n",
        "      validation_data = valid_flow,\n",
        "      validation_steps = valid_steps,\n",
        "      callbacks=[earlystop_callback, checkpoint_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbNZagWLi6uL",
        "outputId": "178f31fc-68d8-4ffb-f90a-3985591bd9f2"
      },
      "id": "BbNZagWLi6uL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4977 - accuracy: 0.7729 \n",
            "Epoch 1: val_loss improved from inf to 11.73476, saving model to model.hdf5\n",
            "15/15 [==============================] - 302s 20s/step - loss: 0.4977 - accuracy: 0.7729 - val_loss: 11.7348 - val_accuracy: 0.4844\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4102 - accuracy: 0.8115 \n",
            "Epoch 2: val_loss improved from 11.73476 to 1.94965, saving model to model.hdf5\n",
            "15/15 [==============================] - 318s 21s/step - loss: 0.4102 - accuracy: 0.8115 - val_loss: 1.9497 - val_accuracy: 0.4583\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.4238 - accuracy: 0.8167 \n",
            "Epoch 3: val_loss did not improve from 1.94965\n",
            "15/15 [==============================] - 314s 21s/step - loss: 0.4238 - accuracy: 0.8167 - val_loss: 2.8346 - val_accuracy: 0.4896\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2988 - accuracy: 0.8760 \n",
            "Epoch 4: val_loss did not improve from 1.94965\n",
            "15/15 [==============================] - 316s 21s/step - loss: 0.2988 - accuracy: 0.8760 - val_loss: 2.4684 - val_accuracy: 0.6302\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - ETA: 0s - loss: 0.2769 - accuracy: 0.8771 \n",
            "Epoch 5: val_loss did not improve from 1.94965\n",
            "15/15 [==============================] - 315s 21s/step - loss: 0.2769 - accuracy: 0.8771 - val_loss: 2.2721 - val_accuracy: 0.5885\n",
            "Epoch 6/10\n",
            " 4/15 [=======>......................] - ETA: 3:45 - loss: 0.3175 - accuracy: 0.8594"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict_generator(test_flow)\n",
        "y_test = test_flow.classes"
      ],
      "metadata": {
        "id": "ZuJsjY08i_O7"
      },
      "id": "ZuJsjY08i_O7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
        "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
        "print()\n",
        "print(metrics.classification_report(y_test, y_pred > 0.5))"
      ],
      "metadata": {
        "id": "bKWO5J-XjFlI"
      },
      "id": "bKWO5J-XjFlI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fd36fe3-67b8-4960-8273-a1358f53e577",
      "metadata": {
        "id": "9fd36fe3-67b8-4960-8273-a1358f53e577"
      },
      "outputs": [],
      "source": [
        "def plot_loss(epochs, loss, val_loss):\n",
        "    plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
        "    plt.plot(epochs, val_loss, 'orange', label = 'Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "def plot_accuracy(epochs, acc, val_acc):\n",
        "    plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "    plt.plot(epochs, val_acc, 'orange', label = 'Validation accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22b83dc9-66ac-42f8-bdf4-f0df49955d00",
      "metadata": {
        "id": "22b83dc9-66ac-42f8-bdf4-f0df49955d00"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4120bdfb-b4be-4c30-a015-bf167aa15f5e",
      "metadata": {
        "id": "4120bdfb-b4be-4c30-a015-bf167aa15f5e"
      },
      "outputs": [],
      "source": [
        "plot_loss(range(1, len(loss) + 1), loss, val_loss)\n",
        "plot_accuracy(range(1, len(loss) + 1), acc, val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f9fc6a-f44f-49d1-aecb-a9aa279dceb4",
      "metadata": {
        "id": "60f9fc6a-f44f-49d1-aecb-a9aa279dceb4"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_flow)\n",
        "y_test = test_flow.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "976fb92d-39a7-4eb1-8ef4-59f5f9be1629",
      "metadata": {
        "id": "976fb92d-39a7-4eb1-8ef4-59f5f9be1629"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"ROC AUC Score:\", metrics.roc_auc_score(y_test, y_pred))\n",
        "\n",
        "print(\"AP Score:\", metrics.average_precision_score(y_test, y_pred))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_pred > 0.5))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}